{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":15231,"status":"ok","timestamp":1726336802642,"user":{"displayName":"何维清","userId":"13222306565952358201"},"user_tz":240},"id":"vJanQk7L8-96","outputId":"72f69881-a72b-4604-f076-ab9a187d3346"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in links: https://data.dgl.ai/wheels/torch-2.3/repo.html\n","Collecting dgl\n","  Downloading https://data.dgl.ai/wheels/torch-2.3/dgl-2.4.0-cp310-cp310-manylinux1_x86_64.whl (6.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgl) (3.3)\n","Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.26.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from dgl) (24.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from dgl) (2.1.4)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (5.9.5)\n","Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.9.1)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from dgl) (6.0.2)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.32.3)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.13.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgl) (4.66.5)\n","Requirement already satisfied: torch<=2.4.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.4.0+cu121)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->dgl) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.3 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->dgl) (2.23.3)\n","Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->dgl) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.8)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2024.8.30)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (3.16.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (1.13.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (2024.6.1)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->dgl) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->dgl) (2024.2)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->dgl) (2024.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->dgl) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<=2.4.0->dgl) (2.1.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<=2.4.0->dgl) (1.3.0)\n","Installing collected packages: dgl\n","Successfully installed dgl-2.4.0\n"]}],"source":["# if your device is cup, install this version\n","pip install  dgl -f https://data.dgl.ai/wheels/torch-2.3/repo.html"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":29932,"status":"ok","timestamp":1726443104874,"user":{"displayName":"何维清","userId":"13222306565952358201"},"user_tz":240},"id":"E1lGnWGmMZ8S","outputId":"90effa63-c395-4ff5-ae88-781f7c03c292"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in links: https://data.dgl.ai/wheels/torch-2.3/cu121/repo.html\n","Collecting dgl\n","  Downloading https://data.dgl.ai/wheels/torch-2.3/cu121/dgl-2.4.0%2Bcu121-cp310-cp310-manylinux1_x86_64.whl (355.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m355.1/355.1 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgl) (3.3)\n","Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.26.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from dgl) (24.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from dgl) (2.1.4)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (5.9.5)\n","Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.9.1)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from dgl) (6.0.2)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.32.3)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.13.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgl) (4.66.5)\n","Requirement already satisfied: torch<=2.4.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.4.0+cu121)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->dgl) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.3 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->dgl) (2.23.3)\n","Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->dgl) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.8)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2024.8.30)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (3.16.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (1.13.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (2024.6.1)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->dgl) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->dgl) (2024.2)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->dgl) (2024.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->dgl) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<=2.4.0->dgl) (2.1.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<=2.4.0->dgl) (1.3.0)\n","Installing collected packages: dgl\n","Successfully installed dgl-2.4.0+cu121\n"]}],"source":["# if cuda is available, install this version\n","pip install  dgl -f https://data.dgl.ai/wheels/torch-2.3/cu121/repo.html"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8259,"status":"ok","timestamp":1726443120079,"user":{"displayName":"何维清","userId":"13222306565952358201"},"user_tz":240},"id":"P9FkE9ad90xK","outputId":"b5c7d91e-b0b1-4534-c561-c2d7ced2b00a"},"outputs":[{"name":"stderr","output_type":"stream","text":["DGL backend not selected or invalid.  Assuming PyTorch for now.\n"]},{"name":"stdout","output_type":"stream","text":["Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n"]}],"source":["import dgl\n","import torch\n","import torch.nn as nn\n","import dgl.nn as dglnn\n","import torch.nn.functional as F\n","import dgl.function as fn\n","from dgl.nn import RelGraphConv\n","import random\n","from tqdm import tqdm\n","import numpy as np"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3316,"status":"ok","timestamp":1726443152114,"user":{"displayName":"何维清","userId":"13222306565952358201"},"user_tz":240},"id":"8bhz2D9bFBWH","outputId":"ef906b1e-8490-442c-e5c5-836c37643654"},"outputs":[{"name":"stdout","output_type":"stream","text":["Done loading data from cached files.\n"]}],"source":["ds = dgl.data.CSVDataset('data/sdoh_drug')\n","g = ds[0]"]},{"cell_type":"markdown","metadata":{},"source":["### Description of the graph"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":499,"status":"ok","timestamp":1726443154716,"user":{"displayName":"何维清","userId":"13222306565952358201"},"user_tz":240},"id":"io_LvrDg9_oV","outputId":"9ae7610c-ab54-405a-bd7d-f18a6dc7c937"},"outputs":[{"data":{"text/plain":["Graph(num_nodes={'disease': 4197, 'drug': 2522, 'phenotype': 1171, 'sdoh': 19},\n","      num_edges={('disease', 'disease_drug', 'drug'): 1009510, ('disease', 'disease_phenotype', 'phenotype'): 494, ('drug', 'drug_disease', 'disease'): 1009510, ('drug', 'drug_phenotype', 'phenotype'): 34685, ('drug', 'drug_sdoh', 'sdoh'): 27965, ('phenotype', 'phenotype_disease', 'disease'): 494, ('phenotype', 'phenotype_drug', 'drug'): 34685, ('sdoh', 'sdoh_drug', 'drug'): 27965},\n","      metagraph=[('disease', 'drug', 'disease_drug'), ('disease', 'phenotype', 'disease_phenotype'), ('drug', 'disease', 'drug_disease'), ('drug', 'phenotype', 'drug_phenotype'), ('drug', 'sdoh', 'drug_sdoh'), ('phenotype', 'disease', 'phenotype_disease'), ('phenotype', 'drug', 'phenotype_drug'), ('sdoh', 'drug', 'sdoh_drug')])"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["g"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":273,"status":"ok","timestamp":1726443155988,"user":{"displayName":"何维清","userId":"13222306565952358201"},"user_tz":240},"id":"pm2Qbr75pX2a"},"outputs":[],"source":["sdoh_checks = [[3, 14], [4, 16], [7, 18], [1, 11], [2, 12]] # economic, education, environment, community\n","sdoh_lists = ['economic', 'education', 'environment', 'community_absent', 'community_present']"]},{"cell_type":"markdown","metadata":{},"source":["### Define some functions, mainly for seperating test and train data"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":26,"status":"ok","timestamp":1726443157281,"user":{"displayName":"何维清","userId":"13222306565952358201"},"user_tz":240},"id":"Ett23IFrC0BA"},"outputs":[],"source":["def get_unconnected(g, sdoh_check, etype, nodes = 'disease', print_out=True):\n","  target_nodes = g.nodes(nodes)\n","  connected_target_1,_ = g.in_edges(sdoh_check[0], etype=etype) # known the dst, get the src.\n","  connected_target_2,_ = g.in_edges(sdoh_check[1], etype=etype)\n","  connected_target = set(connected_target_1.tolist()) | set(connected_target_2.tolist())\n","  unconnected_target = [node for node in target_nodes.cpu().numpy() if node not in connected_target]\n","  if print_out:\n","      print(f'the number of unconnected {nodes} nodes is: ',len(unconnected_target))\n","  return unconnected_target\n","\n","def choose_dst(g, unconnected_target, n, etype, dst='phenotype', print_out=True):\n","    edges_dst = []\n","    edges_src = []\n","    for nodes in unconnected_target:\n","        connected_dst, src = g.in_edges(nodes, etype=etype)\n","        edges_dst = edges_dst + connected_dst.tolist()\n","        edges_src = edges_src + src.tolist()\n","\n","    n_sample = len(edges_dst) // n\n","    if print_out:\n","        print('number of edges to be selected:', n_sample)\n","\n","    mask_dst = random.sample(range(len(edges_dst)), n_sample)\n","\n","    edges_to_remove = [edges_dst[i] for i in mask_dst]\n","    sel_unsrc = [edges_src[i] for i in mask_dst]\n","\n","    return sel_unsrc, edges_to_remove\n","\n","def test_graph_construct(g, sdoh_check, n, etype_sdoh, etype, nodes='disease', dst='phenotype', print_out=True, device='cpu'):\n","  inverse_etype_sdoh = etype_sdoh.split('_')[1] + '_' + etype_sdoh.split('_')[0]\n","  unconnected_target = get_unconnected(g, sdoh_check, etype_sdoh, nodes, print_out=print_out)\n","  choosed_src, choosed_dst = choose_dst(g, unconnected_target, n, etype, dst, print_out=print_out)\n","  num_nodes_dict = {ntype: g.number_of_nodes(ntype) for ntype in g.ntypes}\n","  g0 = g.clone()\n","  g0.add_edges(choosed_src, [sdoh_check[0]] * len(choosed_src), etype = etype_sdoh)\n","  g0.add_edges([sdoh_check[0]] * len(choosed_src), choosed_src, etype = inverse_etype_sdoh)\n","  g1 = g.clone()\n","  g1.add_edges(choosed_src, [sdoh_check[1]] * len(choosed_src), etype = etype_sdoh)\n","  g1.add_edges([sdoh_check[1]] * len(choosed_src), choosed_src, etype = inverse_etype_sdoh)\n","  g0 = g0.to(device)\n","  g1 = g1.to(device)\n","  choosed_src = torch.tensor(choosed_src).to(device)\n","  choosed_dst = torch.tensor(choosed_dst).to(device)\n","\n","  return g0, g1, choosed_src, choosed_dst\n","\n","\n","def fair_loss(pred0, pred1):\n","    sum_squared_diff = torch.sum((pred0 - pred1) ** 2)\n","\n","    return sum_squared_diff\n","\n","def compute_mrr(pos_score, neg_score):\n","  num_edges = pos_score.shape[0]\n","  neg_score = neg_score.view(num_edges, -1).detach().cpu().numpy()\n","  pos_score = pos_score.detach().cpu().numpy()\n","  mrr = []\n","  for i in range(len(pos_score)):\n","    rank = np.sum(neg_score[i] > pos_score[i]) + 1\n","    mrr.append(1/rank)\n","  return mrr\n","\n","def compute_loss(pos_score, neg_score):\n","    # Margin loss\n","    n_edges = pos_score.shape[0]\n","    return (1 - pos_score + neg_score.view(n_edges, -1)).clamp(min=0).mean()\n","\n","def construct_negative_graph(graph, k, etype, device='cpu'):\n","    utype, _, vtype = etype\n","    src, dst = graph.edges(etype=etype)\n","    neg_src = src.repeat_interleave(k)\n","    neg_dst = torch.randint(0, graph.num_nodes(vtype), (len(src) * k,)).to(device)\n","    return dgl.heterograph(\n","        {etype: (neg_src, neg_dst)},\n","        num_nodes_dict={ntype: graph.num_nodes(ntype) for ntype in graph.ntypes}).to(device)"]},{"cell_type":"markdown","metadata":{},"source":["### The class for heterogeneous-GCN model"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":538,"status":"ok","timestamp":1726443159680,"user":{"displayName":"何维清","userId":"13222306565952358201"},"user_tz":240},"id":"QbfFuqP8FWJV"},"outputs":[],"source":["class HeteroDotProductPredictor(nn.Module):\n","    def forward(self, graph, h, etype):\n","        # h contains the node representations for each node type computed from\n","        # the GNN defined in the previous section (Section 5.1).\n","        with graph.local_scope():\n","            graph.ndata['h'] = h\n","            graph.apply_edges(fn.u_dot_v('h', 'h', 'score'), etype=etype)\n","            return graph.edges[etype].data['score']\n","\n","\n","class RGCN(nn.Module):\n","    def __init__(self, in_feats, hid_feats, out_feats, rel_names):\n","        super().__init__()\n","\n","        self.conv1 = dglnn.HeteroGraphConv({\n","            rel: dglnn.GraphConv(in_feats, hid_feats)\n","            for rel in rel_names}, aggregate='sum')\n","        self.conv2 = dglnn.HeteroGraphConv({\n","            rel: dglnn.GraphConv(hid_feats, out_feats)\n","            for rel in rel_names}, aggregate='sum')\n","\n","    def forward(self, graph, inputs, edge_weights):\n","        #inputs are features of nodes\n","        h = self.conv1(graph, inputs, mod_kwargs={\n","            'sdoh_drug': {'edge_weight': edge_weights['sdoh_drug']},\n","            'drug_sdoh': {'edge_weight': edge_weights['drug_sdoh']}\n","        })\n","        h = {k: F.relu(v) for k, v in h.items()}\n","        h = self.conv2(graph, h)\n","        return h\n","\n","\n","class Model(nn.Module):\n","    def __init__(self, in_features, hid_feats, out_features, rel_names):\n","        super().__init__()\n","        self.sage = RGCN(in_features, hid_feats, out_features, rel_names)\n","        self.pred = HeteroDotProductPredictor()\n","\n","    def forward(self, g, neg_g, x, e, etype):\n","        h = self.sage(g, x, e)\n","        return self.pred(g, h, etype), self.pred(neg_g, h, etype)\n","\n","\n","class Bias_Predictor(nn.Module):\n","    def forward(self, graph, h, src, dst, etype):\n","        # h contains the node representations for each node type computed from\n","        # the GNN defined in the previous section (Section 5.1).\n","        with graph.local_scope():\n","            graph.ndata['h'] = h\n","            graph.apply_edges(fn.u_dot_v('h', 'h', 'score'), edges=(src, dst), etype=etype)\n","            return graph.edges[etype].data['score']\n","\n","class RGCN_noweight(nn.Module):\n","    def __init__(self, in_feats, hid_feats, out_feats, rel_names):\n","        super().__init__()\n","\n","        self.conv1 = dglnn.HeteroGraphConv({\n","            rel: dglnn.GraphConv(in_feats, hid_feats)\n","            for rel in rel_names}, aggregate='sum')\n","        self.conv2 = dglnn.HeteroGraphConv({\n","            rel: dglnn.GraphConv(hid_feats, out_feats)\n","            for rel in rel_names}, aggregate='sum')\n","\n","    def forward(self, graph, inputs):\n","        # inputs are features of nodes\n","        h = self.conv1(graph, inputs)\n","        h = {k: F.relu(v) for k, v in h.items()}\n","        h = self.conv2(graph, h)\n","        return h\n","\n","\n","class Model_noweight(nn.Module):\n","    def __init__(self, in_features, hid_feats, out_features, rel_names):\n","        super().__init__()\n","        self.sage = RGCN_noweight(in_features, hid_feats, out_features, rel_names)\n","        self.pred = HeteroDotProductPredictor()\n","\n","    def forward(self, g, neg_g, x, etype):\n","        h = self.sage(g, x)\n","        return self.pred(g, h, etype), self.pred(neg_g, h, etype)"]},{"cell_type":"markdown","metadata":{},"source":["### The class for fairness model"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":523,"status":"ok","timestamp":1726443165416,"user":{"displayName":"何维清","userId":"13222306565952358201"},"user_tz":240},"id":"FeotYEelAcXH"},"outputs":[],"source":["class Model_fair(nn.Module):\n","    def __init__(self, in_features, hid_feats, out_features, rel_names, num_edges, emb_model):\n","        super().__init__()\n","        self.rgcn = RGCN(in_features, hid_feats, out_features, rel_names)\n","        self.rgcn.load_state_dict(torch.load(emb_model))\n","        # Freeze the parameters of the RGCN model to prevent them from being updated\n","        for param in self.rgcn.parameters():\n","            param.requires_grad = False\n","\n","        self.influence_weights = nn.Parameter(torch.rand(num_edges))\n","        self.influenced_by_weights = nn.Parameter(torch.rand(num_edges))\n","        self.get_bias = Bias_Predictor()\n","        self.num_edges = num_edges\n","\n","\n","    def forward(self, g0, g1, x, unconnected_drug, choosed_disease, etype):\n","        num_edges_test = g0.num_edges('sdoh_drug')\n","        num_edges = self.num_edges\n","\n","        # Compute the mean as a scalar and create tensors using it, ensuring gradient tracking\n","        edge_inf_mean = torch.mean(self.influence_weights)\n","        edge_infby_mean = torch.mean(self.influenced_by_weights)\n","\n","    # Construct the influence weights tensor\n","        weight_inf = torch.cat(\n","            [self.influence_weights, edge_inf_mean.expand(num_edges_test - num_edges)],\n","            dim=0\n","        )\n","\n","        # Construct the influenced_by weights tensor\n","        weight_infby = torch.cat(\n","            [self.influenced_by_weights, edge_infby_mean.expand(num_edges_test - num_edges)],\n","            dim=0\n","        )\n","        weight_inf.requires_grad_(True)\n","        weight_infby.requires_grad_(True)\n","\n","        e = {'sdoh_drug': weight_inf, 'drug_sdoh': weight_infby}\n","\n","        h0 = self.rgcn(g0, x, e)\n","        h1 = self.rgcn(g1, x, e)\n","\n","        return self.get_bias(g0, h0, unconnected_drug, choosed_disease, etype), self.get_bias(g1, h1, unconnected_drug, choosed_disease, etype), e"]},{"cell_type":"markdown","metadata":{"id":"js_0FE4LHUgW"},"source":["### Detect the bias and then debias"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":272360,"status":"ok","timestamp":1726443468201,"user":{"displayName":"何维清","userId":"13222306565952358201"},"user_tz":240},"id":"dxTT0PRaFXst","outputId":"5fce2d20-efd2-4331-8d83-39002bca8eee"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using device: cuda\n","the number of unconnected drug nodes is:  743\n","number of edges to be selected: 5285\n"]},{"name":"stderr","output_type":"stream","text":[" 20%|██        | 10/50 [00:07<00:27,  1.44it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 10, Loss: 0.9707483649253845\n"]},{"name":"stderr","output_type":"stream","text":[" 40%|████      | 20/50 [00:13<00:15,  1.88it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 20, Loss: 0.8443091511726379\n"]},{"name":"stderr","output_type":"stream","text":[" 60%|██████    | 30/50 [00:18<00:10,  1.93it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 30, Loss: 0.7012432217597961\n"]},{"name":"stderr","output_type":"stream","text":[" 80%|████████  | 40/50 [00:24<00:05,  1.81it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 40, Loss: 0.7041712403297424\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 50/50 [00:29<00:00,  1.68it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 50, Loss: 0.677746057510376\n"]},{"name":"stderr","output_type":"stream","text":["\n","<ipython-input-11-efffe1902b45>:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  self.rgcn.load_state_dict(torch.load(emb_model))\n"]},{"name":"stdout","output_type":"stream","text":["the bias of economic is: 92.3972\n","-----------------------------------------------------\n","begin debias\n","-----------------------------------------------------\n"]},{"name":"stderr","output_type":"stream","text":[" 10%|█         | 10/100 [00:06<00:51,  1.76it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 10, Loss: 0.21372807025909424\n"]},{"name":"stderr","output_type":"stream","text":[" 20%|██        | 20/100 [00:11<00:39,  2.00it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 20, Loss: 0.22903236746788025\n"]},{"name":"stderr","output_type":"stream","text":[" 30%|███       | 30/100 [00:17<00:45,  1.53it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 30, Loss: 0.17518804967403412\n"]},{"name":"stderr","output_type":"stream","text":[" 40%|████      | 40/100 [00:23<00:33,  1.81it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 40, Loss: 0.16596993803977966\n"]},{"name":"stderr","output_type":"stream","text":[" 50%|█████     | 50/100 [00:28<00:24,  2.01it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 50, Loss: 0.15285244584083557\n"]},{"name":"stderr","output_type":"stream","text":[" 60%|██████    | 60/100 [00:34<00:21,  1.86it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 60, Loss: 0.14617611467838287\n"]},{"name":"stderr","output_type":"stream","text":[" 70%|███████   | 70/100 [00:39<00:15,  1.94it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 70, Loss: 0.1381361037492752\n"]},{"name":"stderr","output_type":"stream","text":[" 80%|████████  | 80/100 [00:44<00:12,  1.54it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 80, Loss: 0.131632998585701\n"]},{"name":"stderr","output_type":"stream","text":[" 90%|█████████ | 90/100 [00:50<00:05,  1.95it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 90, Loss: 0.12501919269561768\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 100/100 [00:55<00:00,  1.81it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 100, Loss: 0.11868274956941605\n","the af-bias of economic is: 6.9102345\n","the bias improvement is: 85.48697\n","-----------------------------------------------------\n","the number of unconnected drug nodes is:  83\n","number of edges to be selected: 221\n"]},{"name":"stderr","output_type":"stream","text":[" 20%|██        | 10/50 [00:06<00:22,  1.80it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 10, Loss: 0.9727317094802856\n"]},{"name":"stderr","output_type":"stream","text":[" 40%|████      | 20/50 [00:11<00:15,  1.89it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 20, Loss: 0.8555586934089661\n"]},{"name":"stderr","output_type":"stream","text":[" 60%|██████    | 30/50 [00:18<00:12,  1.62it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 30, Loss: 0.7042846083641052\n"]},{"name":"stderr","output_type":"stream","text":[" 80%|████████  | 40/50 [00:23<00:05,  1.91it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 40, Loss: 0.7072519659996033\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 50/50 [00:29<00:00,  1.71it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 50, Loss: 0.6783732771873474\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["the bias of education is: 67.94933\n","-----------------------------------------------------\n","begin debias\n","-----------------------------------------------------\n"]},{"name":"stderr","output_type":"stream","text":[" 11%|█         | 11/100 [00:01<00:09,  9.89it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 10, Loss: 40.27069854736328\n"]},{"name":"stderr","output_type":"stream","text":[" 21%|██        | 21/100 [00:02<00:08,  9.09it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 20, Loss: 18.905010223388672\n"]},{"name":"stderr","output_type":"stream","text":[" 31%|███       | 31/100 [00:03<00:07,  9.43it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 30, Loss: 6.914376735687256\n"]},{"name":"stderr","output_type":"stream","text":[" 41%|████      | 41/100 [00:04<00:06,  9.12it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 40, Loss: 1.692331314086914\n"]},{"name":"stderr","output_type":"stream","text":[" 51%|█████     | 51/100 [00:05<00:05,  9.49it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 50, Loss: 0.18180561065673828\n"]},{"name":"stderr","output_type":"stream","text":[" 61%|██████    | 61/100 [00:06<00:04,  9.37it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 60, Loss: 0.017335431650280952\n"]},{"name":"stderr","output_type":"stream","text":[" 71%|███████   | 71/100 [00:07<00:03,  9.45it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 70, Loss: 0.0600266270339489\n"]},{"name":"stderr","output_type":"stream","text":[" 81%|████████  | 81/100 [00:08<00:02,  9.47it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 80, Loss: 0.05126767233014107\n"]},{"name":"stderr","output_type":"stream","text":[" 91%|█████████ | 91/100 [00:09<00:00,  9.41it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 90, Loss: 0.025759253650903702\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 100/100 [00:10<00:00,  9.36it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 100, Loss: 0.014878681860864162\n","the af-bias of education is: 8.831992\n","the bias improvement is: 59.11734\n","-----------------------------------------------------\n","the number of unconnected drug nodes is:  431\n","number of edges to be selected: 2013\n"]},{"name":"stderr","output_type":"stream","text":[" 20%|██        | 10/50 [00:06<00:21,  1.83it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 10, Loss: 0.961759090423584\n"]},{"name":"stderr","output_type":"stream","text":[" 40%|████      | 20/50 [00:11<00:15,  1.92it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 20, Loss: 0.8238744139671326\n"]},{"name":"stderr","output_type":"stream","text":[" 60%|██████    | 30/50 [00:17<00:12,  1.65it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 30, Loss: 0.6943209171295166\n"]},{"name":"stderr","output_type":"stream","text":[" 80%|████████  | 40/50 [00:22<00:05,  1.88it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 40, Loss: 0.6961208581924438\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 50/50 [00:28<00:00,  1.73it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 50, Loss: 0.6705749034881592\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["the bias of environment is: 158.30151\n","-----------------------------------------------------\n","begin debias\n","-----------------------------------------------------\n"]},{"name":"stderr","output_type":"stream","text":[" 10%|█         | 10/100 [00:02<00:24,  3.69it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 10, Loss: 3.061708688735962\n"]},{"name":"stderr","output_type":"stream","text":[" 20%|██        | 20/100 [00:05<00:21,  3.67it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 20, Loss: 0.40761592984199524\n"]},{"name":"stderr","output_type":"stream","text":[" 30%|███       | 30/100 [00:08<00:18,  3.72it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 30, Loss: 0.06296263635158539\n"]},{"name":"stderr","output_type":"stream","text":[" 40%|████      | 40/100 [00:11<00:20,  2.99it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 40, Loss: 0.15703216195106506\n"]},{"name":"stderr","output_type":"stream","text":[" 50%|█████     | 50/100 [00:14<00:15,  3.27it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 50, Loss: 0.0821153074502945\n"]},{"name":"stderr","output_type":"stream","text":[" 60%|██████    | 60/100 [00:17<00:10,  3.80it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 60, Loss: 0.044855885207653046\n"]},{"name":"stderr","output_type":"stream","text":[" 70%|███████   | 70/100 [00:19<00:08,  3.69it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 70, Loss: 0.04944872111082077\n"]},{"name":"stderr","output_type":"stream","text":[" 80%|████████  | 80/100 [00:22<00:05,  3.80it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 80, Loss: 0.04565387964248657\n"]},{"name":"stderr","output_type":"stream","text":[" 90%|█████████ | 90/100 [00:25<00:03,  2.76it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 90, Loss: 0.0437614768743515\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 100/100 [00:28<00:00,  3.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 100, Loss: 0.04360765963792801\n","the af-bias of environment is: 20.357857\n","the bias improvement is: 137.94366\n","-----------------------------------------------------\n","the number of unconnected drug nodes is:  90\n","number of edges to be selected: 257\n"]},{"name":"stderr","output_type":"stream","text":[" 20%|██        | 10/50 [00:05<00:21,  1.88it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 10, Loss: 0.9548438787460327\n"]},{"name":"stderr","output_type":"stream","text":[" 40%|████      | 20/50 [00:11<00:20,  1.44it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 20, Loss: 0.804585874080658\n"]},{"name":"stderr","output_type":"stream","text":[" 60%|██████    | 30/50 [00:16<00:10,  1.87it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 30, Loss: 0.6969287395477295\n"]},{"name":"stderr","output_type":"stream","text":[" 80%|████████  | 40/50 [00:22<00:06,  1.55it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 40, Loss: 0.692660927772522\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 50/50 [00:28<00:00,  1.74it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 50, Loss: 0.6697618365287781\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["the bias of community_absent is: 33.1603\n","-----------------------------------------------------\n","begin debias\n","-----------------------------------------------------\n"]},{"name":"stderr","output_type":"stream","text":[" 11%|█         | 11/100 [00:01<00:09,  9.72it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 10, Loss: 0.13002590835094452\n"]},{"name":"stderr","output_type":"stream","text":[" 21%|██        | 21/100 [00:02<00:08,  9.40it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 20, Loss: 0.07810613512992859\n"]},{"name":"stderr","output_type":"stream","text":[" 31%|███       | 31/100 [00:03<00:07,  8.73it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 30, Loss: 0.08259256929159164\n"]},{"name":"stderr","output_type":"stream","text":[" 41%|████      | 41/100 [00:04<00:06,  8.79it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 40, Loss: 0.01102911401540041\n"]},{"name":"stderr","output_type":"stream","text":[" 51%|█████     | 51/100 [00:05<00:05,  8.57it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 50, Loss: 0.004411631263792515\n"]},{"name":"stderr","output_type":"stream","text":[" 61%|██████    | 61/100 [00:07<00:05,  7.29it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 60, Loss: 0.0062393490225076675\n"]},{"name":"stderr","output_type":"stream","text":[" 71%|███████   | 71/100 [00:08<00:04,  6.79it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 70, Loss: 0.004907031077891588\n"]},{"name":"stderr","output_type":"stream","text":[" 81%|████████  | 81/100 [00:09<00:02,  7.77it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 80, Loss: 0.003847262589260936\n"]},{"name":"stderr","output_type":"stream","text":[" 91%|█████████ | 91/100 [00:10<00:01,  8.95it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 90, Loss: 0.003485308028757572\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 100/100 [00:11<00:00,  8.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 100, Loss: 0.003383526811376214\n","the af-bias of community_absent is: 3.1474442\n","the bias improvement is: 30.012857\n","-----------------------------------------------------\n","the number of unconnected drug nodes is:  115\n","number of edges to be selected: 488\n"]},{"name":"stderr","output_type":"stream","text":[" 20%|██        | 10/50 [00:05<00:21,  1.85it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 10, Loss: 0.9680657386779785\n"]},{"name":"stderr","output_type":"stream","text":[" 40%|████      | 20/50 [00:11<00:19,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 20, Loss: 0.8414145708084106\n"]},{"name":"stderr","output_type":"stream","text":[" 60%|██████    | 30/50 [00:17<00:10,  1.86it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 30, Loss: 0.7030667662620544\n"]},{"name":"stderr","output_type":"stream","text":[" 80%|████████  | 40/50 [00:23<00:06,  1.49it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 40, Loss: 0.7056998610496521\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 50/50 [00:28<00:00,  1.74it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 50, Loss: 0.6787728071212769\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["the bias of community_present is: 5.2963195\n","-----------------------------------------------------\n","begin debias\n","-----------------------------------------------------\n"]},{"name":"stderr","output_type":"stream","text":[" 11%|█         | 11/100 [00:01<00:10,  8.89it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 10, Loss: 0.024200718849897385\n"]},{"name":"stderr","output_type":"stream","text":[" 21%|██        | 21/100 [00:02<00:09,  7.94it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 20, Loss: 0.004015009850263596\n"]},{"name":"stderr","output_type":"stream","text":[" 31%|███       | 31/100 [00:03<00:08,  8.34it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 30, Loss: 0.006461286451667547\n"]},{"name":"stderr","output_type":"stream","text":[" 41%|████      | 41/100 [00:04<00:07,  8.28it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 40, Loss: 0.004213042091578245\n"]},{"name":"stderr","output_type":"stream","text":[" 51%|█████     | 51/100 [00:06<00:07,  6.49it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 50, Loss: 0.003784944536164403\n"]},{"name":"stderr","output_type":"stream","text":[" 61%|██████    | 61/100 [00:08<00:06,  6.03it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 60, Loss: 0.003745615016669035\n"]},{"name":"stderr","output_type":"stream","text":[" 71%|███████   | 71/100 [00:09<00:03,  7.87it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 70, Loss: 0.0036351175513118505\n"]},{"name":"stderr","output_type":"stream","text":[" 81%|████████  | 81/100 [00:10<00:02,  8.20it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 80, Loss: 0.003524302737787366\n"]},{"name":"stderr","output_type":"stream","text":[" 91%|█████████ | 91/100 [00:11<00:01,  7.92it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 90, Loss: 0.003424620721489191\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 100/100 [00:13<00:00,  7.63it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 100, Loss: 0.0033313476014882326\n","the af-bias of community_present is: 1.3678743\n","the bias improvement is: 3.9284453\n","-----------------------------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(f'Using device: {device}')\n","num_nodes_dict = {ntype: g.number_of_nodes(ntype) for ntype in g.ntypes}\n","n_hetero_features = 20\n","g = g.to(device)\n","g.nodes['disease'].data['feature'] = torch.randn(num_nodes_dict['disease'], n_hetero_features).to(device)\n","g.nodes['drug'].data['feature'] = torch.randn(num_nodes_dict['drug'], n_hetero_features).to(device)\n","g.nodes['sdoh'].data['feature'] = torch.randn(num_nodes_dict['sdoh'], n_hetero_features).to(device)\n","g.nodes['phenotype'].data['feature'] = torch.randn(num_nodes_dict['phenotype'], n_hetero_features).to(device)\n","edge_weights = {'sdoh_drug': torch.ones(g.num_edges('sdoh_drug')).to(device),\n","                'drug_sdoh': torch.ones(g.num_edges('drug_sdoh')).to(device)}\n","\n","\n","for i in range(len(sdoh_checks)):\n","    test0, test1, test_drug, test_disease = test_graph_construct(g, sdoh_checks[i], 5, 'drug_sdoh', 'disease_drug', nodes='drug', dst='disease', device=device)\n","    e_reid_ass = g.edge_ids(test_drug,test_disease, etype='drug_disease')\n","    e_reid_assd = g.edge_ids(test_disease, test_drug, etype='disease_drug')\n","\n","    train_g = dgl.remove_edges(g, e_reid_ass, etype='drug_disease')\n","    train_g = dgl.remove_edges(train_g, e_reid_assd, etype='disease_drug')\n","\n","\n","    k = 20\n","    model = Model(20, 50, 20, g.etypes).to(device)\n","    disease_feats = train_g.nodes['disease'].data['feature']\n","    drug_feats = train_g.nodes['drug'].data['feature']\n","    sdoh_feats = train_g.nodes['sdoh'].data['feature']\n","    phenotype_feats = train_g.nodes['phenotype'].data['feature']\n","\n","    node_features = {'disease': disease_feats, 'drug': drug_feats, 'sdoh': sdoh_feats, 'phenotype': phenotype_feats} # g, train_g, and all the text set share the same node_features, since the nodes are all the same.\n","    opt = torch.optim.Adam(model.parameters())\n","    for epoch in tqdm(range(50)):\n","        negative_graph = construct_negative_graph(train_g, k, ('drug', 'drug_disease', 'disease'), device=device)\n","        pos_score, neg_score = model(train_g, negative_graph, node_features, edge_weights, ('drug', 'drug_disease', 'disease'))\n","        loss = compute_loss(pos_score, neg_score)\n","        opt.zero_grad()\n","        loss.backward()\n","        opt.step()\n","        if (epoch + 1) % 10 == 0:\n","                print(f'Epoch {epoch + 1}, Loss: {loss.item()}')\n","\n","    torch.save(model.sage.state_dict(), f'/content/drive/MyDrive/KG/model/emb_model-{sdoh_lists[i]}.pth')\n","\n","    model.eval()\n","    edge_weights_test = {'sdoh_drug': torch.ones(test0.num_edges('sdoh_drug')).to(device),\n","                    'drug_sdoh': torch.ones(test0.num_edges('drug_sdoh')).to(device)}\n","    with torch.no_grad():\n","      h0 = model.sage(test0, node_features, edge_weights_test)\n","      h1 = model.sage(test1, node_features, edge_weights_test)\n","      pred0 = Bias_Predictor()(test0, h0, test_drug, test_disease, ('drug', 'drug_disease', 'disease'))\n","      pred1 = Bias_Predictor()(test1, h1, test_drug, test_disease, ('drug', 'drug_disease', 'disease'))\n","\n","      sum_of_differences = torch.sum(torch.abs(pred0 - pred1))\n","    print(f'the bias of {sdoh_lists[i]} is:', sum_of_differences.detach().cpu().numpy())\n","\n","    print('-----------------------------------------------------')\n","    print('begin debias')\n","    print('-----------------------------------------------------')\n","    debias_model = Model_fair(20, 50, 20, train_g.etypes, train_g.num_edges('drug_sdoh'), f'/content/drive/MyDrive/KG/model/emb_model-{sdoh_lists[i]}.pth').to(device)\n","    opt = torch.optim.Adam(debias_model.parameters())\n","    for epoch in tqdm(range(100)):\n","        g0, g1, unconnected_drug, choosed_disease = test_graph_construct(train_g, sdoh_checks[i], 1, 'drug_sdoh', 'disease_drug', nodes='drug', dst='disease', print_out=False, device=device)\n","        pred0, pred1, e = debias_model(g0, g1, node_features, unconnected_drug, choosed_disease, ('drug', 'drug_disease', 'disease'))\n","        loss = fair_loss(pred0, pred1)\n","        opt.zero_grad()\n","        loss.backward()\n","        opt.step()\n","        if (epoch + 1) % 10 == 0:\n","                print(f'Epoch {epoch + 1}, Loss: {loss.item()}')\n","\n","    debias_model.eval()\n","    with torch.no_grad():\n","      e_inf = e['sdoh_drug'][:train_g.num_edges('sdoh_drug')]\n","      e_infby = e['drug_sdoh'][:train_g.num_edges('drug_sdoh')]\n","      edge_inf_mean = torch.mean(e_inf)\n","      edge_infby_mean = torch.mean(e_infby)\n","      weight_inf = torch.cat(\n","                [e_inf, edge_inf_mean.expand(len(test_drug))],\n","                dim=0)\n","      weight_infby = torch.cat(\n","                [e_infby, edge_infby_mean.expand(len(test_drug))],\n","                dim=0)\n","      edge_weights_test_debias = {'sdoh_drug': weight_inf, 'drug_sdoh': weight_infby}\n","\n","      h0 = debias_model.rgcn(test0, node_features, edge_weights_test_debias)\n","      h1 = debias_model.rgcn(test1, node_features, edge_weights_test_debias)\n","\n","      pred0 = Bias_Predictor()(test0, h0, test_drug, test_disease, ('drug', 'drug_disease', 'disease'))\n","      pred1 = Bias_Predictor()(test1, h1, test_drug, test_disease, ('drug', 'drug_disease', 'disease'))\n","      sum_of_differences_af = torch.sum(torch.abs(pred0 - pred1))\n","    print(f'the af-bias of {sdoh_lists[i]} is:', sum_of_differences_af.detach().cpu().numpy())\n","    print('the bias improvement is:', sum_of_differences.detach().cpu().numpy() - sum_of_differences_af.detach().cpu().numpy())\n","    print('-----------------------------------------------------')"]},{"cell_type":"markdown","metadata":{},"source":["### Check the change of accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":183511,"status":"ok","timestamp":1726344540732,"user":{"displayName":"何维清","userId":"13222306565952358201"},"user_tz":240},"id":"EfWphXCg3n4g","outputId":"51f594ee-95aa-4a79-d5f5-fe4179ecf28f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using device: cuda\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 100/100 [00:57<00:00,  1.73it/s]\n","<ipython-input-11-efffe1902b45>:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  self.rgcn.load_state_dict(torch.load(emb_model))\n"]},{"name":"stdout","output_type":"stream","text":["the mrr of drug-disease is: 0.36064443195857804\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 100/100 [00:58<00:00,  1.70it/s]\n"]},{"name":"stdout","output_type":"stream","text":["after debias the mrr of drug-disease is: 0.3606637619278753\n","the change of mrr is: -1.9329969297265936e-05\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 100/100 [00:09<00:00, 10.25it/s]\n"]},{"name":"stdout","output_type":"stream","text":["after debias the mrr of drug-disease is: 0.360710263841985\n","the change of mrr is: -6.583188340697488e-05\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 100/100 [00:28<00:00,  3.52it/s]\n"]},{"name":"stdout","output_type":"stream","text":["after debias the mrr of drug-disease is: 0.36068759365053904\n","the change of mrr is: -4.316169196100228e-05\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 100/100 [00:09<00:00, 10.25it/s]\n"]},{"name":"stdout","output_type":"stream","text":["after debias the mrr of drug-disease is: 0.3606999860602193\n","the change of mrr is: -5.5554101641264175e-05\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 100/100 [00:11<00:00,  8.57it/s]\n"]},{"name":"stdout","output_type":"stream","text":["after debias the mrr of drug-disease is: 0.3607157620158015\n","the change of mrr is: -7.133005722348429e-05\n"]}],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(f'Using device: {device}')\n","num_nodes_dict = {ntype: g.number_of_nodes(ntype) for ntype in g.ntypes}\n","n_hetero_features = 20\n","g = g.to(device)\n","g.nodes['disease'].data['feature'] = torch.randn(num_nodes_dict['disease'], n_hetero_features).to(device)\n","g.nodes['drug'].data['feature'] = torch.randn(num_nodes_dict['drug'], n_hetero_features).to(device)\n","g.nodes['sdoh'].data['feature'] = torch.randn(num_nodes_dict['sdoh'], n_hetero_features).to(device)\n","g.nodes['phenotype'].data['feature'] = torch.randn(num_nodes_dict['phenotype'], n_hetero_features).to(device)\n","edge_weights = {'sdoh_drug': torch.ones(g.num_edges('sdoh_drug')).to(device),\n","                'drug_sdoh': torch.ones(g.num_edges('drug_sdoh')).to(device)}\n","\n","drug_ids, disease_ids = g.edges(etype='drug_disease')\n","num_edges = drug_ids.shape[0]\n","# Number of edges to sample (1/10 of the total edges)\n","num_test_edges = num_edges // 10\n","# Randomly sample indices for test edges\n","sample_indices = torch.randperm(num_edges)[:num_test_edges]\n","# Get the corresponding drug and disease IDs for the sampled test edges\n","test_drug_ids = drug_ids[sample_indices]\n","test_disease_ids = disease_ids[sample_indices]\n","e_reid_ass = g.edge_ids(test_drug_ids,test_disease_ids, etype='drug_disease')\n","e_reid_assd = g.edge_ids(test_disease_ids, test_drug_ids, etype='disease_drug')\n","train_g = dgl.remove_edges(g, e_reid_ass, etype='drug_disease')\n","train_g = dgl.remove_edges(train_g, e_reid_assd, etype='disease_drug')\n","test_nodes_dict = {'drug':num_nodes_dict['drug'], 'disease':num_nodes_dict['disease']}\n","test_g = dgl.heterograph({('drug', 'drug_disease', 'disease'): (test_drug_ids, test_disease_ids)}, num_nodes_dict=test_nodes_dict)\n","\n","k = 20\n","model = Model(20, 50, 20, g.etypes).to(device)\n","disease_feats = train_g.nodes['disease'].data['feature']\n","drug_feats = train_g.nodes['drug'].data['feature']\n","sdoh_feats = train_g.nodes['sdoh'].data['feature']\n","phenotype_feats = train_g.nodes['phenotype'].data['feature']\n","\n","node_features = {'disease': disease_feats, 'drug': drug_feats, 'sdoh': sdoh_feats, 'phenotype': phenotype_feats} # g, train_g, and all the text set share the same node_features, since the nodes are all the same.\n","opt = torch.optim.Adam(model.parameters())\n","for epoch in tqdm(range(100)):\n","    negative_graph = construct_negative_graph(train_g, k, ('drug', 'drug_disease', 'disease'), device=device)\n","    pos_score, neg_score = model(train_g, negative_graph, node_features, edge_weights, ('drug', 'drug_disease', 'disease'))\n","    loss = compute_loss(pos_score, neg_score)\n","    opt.zero_grad()\n","    loss.backward()\n","    opt.step()\n","    # if (epoch + 1) % 10 == 0:\n","    #       print(f'Epoch {epoch + 1}, Loss: {loss.item()}')\n","torch.save(model.sage.state_dict(), f'/content/drive/MyDrive/KG/model/emb_model-dd.pth')\n","model.eval()\n","with torch.no_grad():\n","    trained_features = model.sage(train_g, node_features, edge_weights)\n","\n","test_features = {'drug': trained_features['drug'], 'disease': trained_features['disease']}\n","neg_graph = construct_negative_graph(test_g, k, ('drug', 'drug_disease', 'disease'), device=device)\n","with torch.no_grad():\n","    pos_score = model.pred(test_g, test_features, ('drug', 'drug_disease', 'disease'))\n","    neg_score = model.pred(neg_graph, test_features, ('drug', 'drug_disease', 'disease'))\n","\n","mrr = compute_mrr(pos_score, neg_score)\n","print(f'the mrr of drug-disease is:', np.mean(mrr))\n","\n","for i in range(len(sdoh_checks)):\n","    debias_model = Model_fair(20, 50, 20, train_g.etypes, train_g.num_edges('drug_sdoh'), f'/content/drive/MyDrive/KG/model/emb_model-dd.pth').to(device)\n","    opt = torch.optim.Adam(debias_model.parameters())\n","    for epoch in tqdm(range(100)):\n","        g0, g1, unconnected_drug, choosed_disease = test_graph_construct(train_g, sdoh_checks[i], 1, 'drug_sdoh', 'disease_drug', nodes='drug', dst='disease', print_out=False, device=device)\n","        pred0, pred1, e = debias_model(g0, g1, node_features, unconnected_drug, choosed_disease, ('drug', 'drug_disease', 'disease'))\n","        loss = fair_loss(pred0, pred1)\n","        opt.zero_grad()\n","        loss.backward()\n","        opt.step()\n","        # if (epoch + 1) % 10 == 0:\n","        #     print(f'Epoch {epoch + 1}, Loss: {loss.item()}')\n","\n","    debias_model.eval()\n","    with torch.no_grad():\n","      e_inf = e['sdoh_drug'][:train_g.num_edges('sdoh_drug')]\n","      e_infby = e['drug_sdoh'][:train_g.num_edges('drug_sdoh')]\n","      edge_weights_test_debias = {'sdoh_drug': e_inf, 'drug_sdoh': e_infby}\n","      h0 = debias_model.rgcn(train_g, node_features, edge_weights_test_debias)\n","\n","    test_features = {'drug': h0['drug'], 'disease': h0['disease']}\n","\n","    with torch.no_grad():\n","      pos_score = model.pred(test_g, test_features, ('drug', 'drug_disease', 'disease'))\n","      neg_score = model.pred(neg_graph, test_features, ('drug', 'drug_disease', 'disease'))\n","\n","    de_mrr = compute_mrr(pos_score, neg_score)\n","    print(f'after debias the mrr of drug-disease is:', np.mean(de_mrr))\n","    print('the change of mrr is:', np.mean(mrr)-np.mean(de_mrr))"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
